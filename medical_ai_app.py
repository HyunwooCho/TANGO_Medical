import streamlit as st
import matplotlib.pyplot as plt
import numpy as np
import nibabel as nib
import io
import torch
import os
import tempfile
import sys
import monai
import pandas as pd
from datetime import datetime
import glob
import zipfile
import io
from pathlib import Path
import asyncio

# Import the training module
from trainer import MedicalImageTrainer
from data import (
    generate_sample_data, 
    download_monai_dataset, 
    prepare_data_preview,
)

# Set page config as the first Streamlit command
st.set_page_config(
    page_title="ğŸ©º ì˜ë£Œ ì˜ìƒ AI í•™ìŠµ ì‹œìŠ¤í…œ", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- setting & utilities
# ë””ë ‰í† ë¦¬ì—ì„œ NIfTI íŒŒì¼ ì°¾ê¸°
def find_nifti_files(directory):
    nifti_files = []
    for ext in ['*.nii', '*.nii.gz']:
        nifti_files.extend(
            glob.glob(os.path.join(directory, '**', ext), recursive=True)
        )
    return nifti_files

# NIfTI íŒŒì¼ ìŒ ì°¾ê¸°(ì´ë¯¸ì§€ & ì„¸ê·¸ë©˜í…Œì´ì…˜)
def find_paired_files(directory):
    all_files = find_nifti_files(directory)

    # íŒŒì¼ëª… íŒ¨í„´ ë¶„ì„í•˜ì—¬ ìŒ ì°¾ê¸°
    pairs = []
    image_pattern_keywords = ['image', 'img', 'volume', 'scan', 't1' 't2', 'flair']
    label_pattern_keywords = ['label', 'seg', 'mask', 'annotation', 'ground']

    # ë°©ë²• 1. ê¸°ë³¸ íŒ¨í„´ (íŒŒì¼ ì´ë¦„ ê¸°ë°˜ìœ¼ë¡œ íŒŒì¼ ìŒ ì°¾ê¸°)
    remaining_files = all_files.copy()
    for img_file in all_files:
        img_name = os.path.basename(img_file).lower()
        img_dir = os.path.dirname(img_file)

        # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸
        if any(kw in img_name for kw in image_pattern_keywords) and img_file in remaining_files:
            # ê°€ëŠ¥í•œ ë ˆì´ë¸” íŒŒì¼ ì°¾ê¸°
            for label_file in all_files:
                if label_file == img_file:
                    continue

                label_name = os.path.basename(label_file).lower()
                label_dir = os.path.dirname(label_file)

                if img_dir == label_dir and any(kw in label_name for kw in label_pattern_keywords):
                    # íŒŒì¼ ì´ë¦„ì—ì„œ ê³µí†µ ë¶€ë¶„ ì°¾ê¸°
                    common_parts = set(img_name.split('_')) & set(label_name.split('_'))
                    if common_parts:
                        pairs.append({"image": img_file, "label": label_file})
                        if img_file in remaining_files:
                            remaining_files.remove(img_file)
                        if label_file in remaining_files:
                            remaining_files.remove(label_file)
                        break

    # ë°©ë²• 2. ìˆœì„œìŒ (ê°™ì€ ì´ë¦„ ë‹¤ë¥¸ ë””ë ‰í† ë¦¬)
    img_dirs = set()
    label_dirs = set()

    # ê°€ëŠ¥í•œ ì´ë¯¸ì§€/ë ˆì´ë¸” ë””ë ‰í† ë¦¬ ì‹ë³„
    for f in all_files:
        dir_name = os.path.basename(os.path.dirname(f)).lower()
        if any(kw in dir_name for kw in image_pattern_keywords):
            img_dirs.add(os.path.dirname(f))
        if any(kw in dir_name for kw in label_pattern_keywords):
            label_dirs.add(os.path.dirname(f))

    # ê°™ì€ íŒŒì¼ëª…ì„ ê°€ì§„ ì´ë¯¸ì§€-ë ˆì´ë¸” ìŒ ì°¾ê¸°
    for img_dir in img_dirs:
        for label_dir in label_dirs:
            img_files = glob.glob(os.path.join(img_dir, '*.nii*'))
            label_files = glob.glob(os.path.join(label_dir, '*.nii*'))
            
            img_names = [os.path.basename(f) for f in img_files]
            label_names = [os.path.basename(f) for f in label_files]
            
            # ê³µí†µ íŒŒì¼ëª… ì°¾ê¸°
            common_names = set(img_names) & set(label_names)
            for name in common_names:
                img_file = os.path.join(img_dir, name)
                label_file = os.path.join(label_dir, name)
                if img_file in remaining_files and label_file in remaining_files:
                    pairs.append({"image": img_file, "label": label_file})
                    remaining_files.remove(img_file)
                    remaining_files.remove(label_file)

    return pairs

# Trainer ì´ˆê¸°í™”
def initialize_trainer(model_type, num_classes, learning_rate, data, batch_size=16, val_ratio=0.2):
    
    # í•™ìŠµê¸° ì´ˆê¸°í™”
    trainer = MedicalImageTrainer(model_type, num_classes, learning_rate)

    # ë°ì´í„° ì¤€ë¹„
    trainer.prepare_data(data, val_ratio=val_ratio, batch_size=batch_size)

    # ëª¨ë¸ ìƒì„±
    trainer.create_model()

    return trainer

# ë¹„ë™ê¸°ì ìœ¼ë¡œ í•™ìŠµ ìˆ˜í–‰(ë¹„ë™ê¸° ì œë„ˆë ˆì´ì…˜ ë°©ì‹)
# async def run_training(trainer, total_epochs, progress_callback):
#     for epoch in range(1, total_epochs+1):
#         async for batch_metrics in trainer.train(epoch):
#             await progress_callback(batch_metrics)

# 

# --- Fix for Streamlit watcher error with torch ---
# Disable file watching to prevent the torch._classes error
if 'STREAMLIT_RUN_PATH' in os.environ:
    import streamlit.watcher.path_watcher
    streamlit.watcher.path_watcher.watch_file = lambda x: None

# Set environment variable to limit file watching
os.environ["STREAMLIT_GLOBAL_WATCHER_MAX_FILES"] = "5000"

# --- Display MONAI version for debugging ---
# st.sidebar.info(f"MONAI version: {monai.__version__}")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# if 'trainer' not in st.session_state:
#     st.session_state.trainer = None
if 'training_in_progress' not in st.session_state:
    st.session_state.training_in_progress = False
if 'current_epoch' not in st.session_state:
    st.session_state.current_epoch = 0
if 'total_epochs' not in st.session_state:
    st.session_state.total_epochs = 0

# --- UI êµ¬ì„± ---
st.title("ğŸ©º ì˜ë£Œ ì˜ìƒ AI í•™ìŠµ ì‹œìŠ¤í…œ")

# íƒ­ ìƒì„±
tabs = st.tabs(["ğŸ”§ ëª¨ë¸ í•™ìŠµ ë° íŒŒì¸íŠœë‹", "ğŸ“Š ì¶”ë¡  ë° ë¶„ì„", "ğŸ“š í•™ìŠµ ìë£Œ"])

with tabs[0]:
    st.header("ëª¨ë¸ í•™ìŠµ ë° íŒŒì¸íŠœë‹")
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("ëª¨ë¸ ì„¤ì •")
        model_type = st.selectbox(
            "ëª¨ë¸ ì•„í‚¤í…ì²˜",
            ["SwinUNETR", "UNET", "SegResNet"],
            help="ì‚¬ìš©í•  ëª¨ë¸ ì•„í‚¤í…ì²˜"
        )
        
        num_classes = st.number_input(
            "ë¶„í•  í´ë˜ìŠ¤ ìˆ˜",
            min_value=2,
            max_value=10,
            value=2,
            help="ë°°ê²½ í´ë˜ìŠ¤ í¬í•¨í•œ ì „ì²´ í´ë˜ìŠ¤ ìˆ˜"
        )

        learning_rate = st.number_input(
            "í•™ìŠµë¥ ",
            min_value=0.00001,
            max_value=0.1,
            value=0.0001,
            format="%.5f",
            help="ëª¨ë¸ í•™ìŠµë¥  (ë‚®ì„ìˆ˜ë¡ ì•ˆì •ì ì´ì§€ë§Œ ëŠë¦¼)"
        )
        
        num_epochs = st.number_input(
            "ì—í¬í¬ ìˆ˜",
            min_value=1,
            max_value=10000,
            value=20,
            help="í•™ìŠµ ë°˜ë³µ íšŸìˆ˜"
        )
        
        batch_size = st.number_input(
            "ë°°ì¹˜ í¬ê¸°",
            min_value=1,
            max_value=1024,
            value=16,
            help="í•œ ë²ˆì— ì²˜ë¦¬í•  ë°ì´í„° ìˆ˜ (ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •)"
        )
        
        # ëª¨ë¸ í•™ìŠµ ì‹œì‘ ë²„íŠ¼
        if st.button("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì´ˆê¸°í™”"):
            if 'training_data' not in st.session_state:
                st.error("í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”.")
            else:
                if 'trainer' not in st.session_state:
                    if 'num_classes' in st.session_state:
                        num_classes = st.session_state.num_classes
                    with st.spinner("ëª¨ë¸ í•™ìŠµì„ ì´ˆê¸°í™” ì¤‘ì…ë‹ˆë‹¤..."):
                        trainer = initialize_trainer(
                            model_type=model_type,
                            num_classes=st.session_state.num_classes if st.session_state.num_classes else num_classes,
                            learning_rate=learning_rate,
                            data=st.session_state.training_data,
                            batch_size=batch_size,
                            val_ratio=st.session_state.val_ratio if st.session_state.val_ratio else None
                        )
                        st.session_state.trainer = trainer
                        st.session_state.training_in_progress = True
                        st.session_state.current_epoch = 0
                        st.session_state.total_epochs = num_epochs
                        # st.rerun()
                        st.success(f"{model_type} ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ì˜€ìŠµë‹ˆë‹¤.")

        # ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ
        st.subheader("ë°ì´í„°ì…‹ ì„¤ì •")
        data_source = st.radio(
            "ë°ì´í„° ì†ŒìŠ¤",
            ["ìƒ˜í”Œ ë°ì´í„° ìƒì„±", "ë°ì´í„°ì…‹ ì—…ë¡œë“œ", "ë””ë ‰í† ë¦¬ ì„ íƒ", "MONAI ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ"],
            help="í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ"
        )
        
        if data_source == "ìƒ˜í”Œ ë°ì´í„° ìƒì„±":
            num_samples = st.number_input(
                "ìƒì„±í•  ìƒ˜í”Œ ìˆ˜",
                min_value=5,
                max_value=50,
                value=10,
                help="ìƒì„±í•  ìƒ˜í”Œ ë°ì´í„° ìˆ˜ (í•™ìŠµìš©)"
            )
            
            if st.button("ìƒ˜í”Œ ë°ì´í„° ìƒì„±"):
                with st.spinner("ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    generated_data = generate_sample_data(num_samples, num_classes)
                    st.session_state.training_data = generated_data
                    st.success(f"{num_samples}ê°œì˜ ìƒ˜í”Œ ë°ì´í„°ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    
        elif data_source == "ë°ì´í„°ì…‹ ì—…ë¡œë“œ":
            uploaded_files = st.file_uploader(
                "í•™ìŠµ ë°ì´í„° ì—…ë¡œë“œ (ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬)",
                type=["nii.gz", "nii", "png", "jpg", "zip"],
                accept_multiple_files=True
            )
            
            if uploaded_files:
                if st.button("ë°ì´í„° ì²˜ë¦¬"):
                    with st.spinner("ì—…ë¡œë“œëœ ë°ì´í„°ë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
                        processed_data = process_uploaded_files(uploaded_files, num_classes)
                        st.session_state.training_data = processed_data
                        st.success(f"{len(uploaded_files)}ê°œì˜ íŒŒì¼ì´ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    
        elif data_source == "ë””ë ‰í† ë¦¬ ì„ íƒ":
            data_dir = st.text_input("ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ ì…ë ¥")
            
            if data_dir and st.button("ë””ë ‰í† ë¦¬ ë°ì´í„° ë¡œë“œ"):
                with st.spinner("ë””ë ‰í† ë¦¬ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤..."):
                    loaded_data = load_data_from_directory(data_dir, num_classes)
                    st.session_state.training_data = loaded_data
                    st.success(f"ë””ë ‰í† ë¦¬ì—ì„œ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤!")
    
        elif data_source == "MONAI ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ":
            monai_dataset_options = [
                # "MedNIST", # ë¶„ë¥˜(classification)ìš© ë°ì´í„°ì…‹ì´ë¯€ë¡œ ë¶„í• (segmentation)ìš©ìœ¼ë¡œ ë³€í™˜ì´ í•„ìš”í•¨
                "Task01_BrainTumour",
                "Task02_Heart",
                "Task03_Liver",
                "Task04_Hippocampus",
                "Task05_Prostate",
                "Task06_Lung",
                "Task07_Pancreas",
                "Task08_HepaticVessel",
                "Task09_Spleen",
                "Task10_Colon"
            ]
            
            selected_dataset = st.selectbox(
                "MONAI ë°ì´í„°ì…‹ ì„ íƒ",
                monai_dataset_options,
                help="ë‹¤ìš´ë¡œë“œí•  MONAI ë°ì´í„°ì…‹ ì„ íƒ"
            )
            
            default_dir = os.path.join(os.getcwd(), "datasets")
            dataset_root_dir = st.text_input(
                "ë°ì´í„°ì…‹ ì €ì¥ ê²½ë¡œ",
                value=default_dir, #"./datasets",
                help="ë‹¤ìš´ë¡œë“œí•œ ë°ì´í„°ì…‹ì„ ì €ì¥í•  ì ˆëŒ€ ê²½ë¡œ (ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±ë©ë‹ˆë‹¤)"
            )
            
            cache_rate = st.slider(
                "ìºì‹œ ë¹„ìœ¨",
                min_value=0.0,
                max_value=1.0,
                value=1.0,
                step=0.1,
                help="ë°ì´í„° ìºì‹± ë¹„ìœ¨ (0: ìºì‹± ì—†ìŒ, 1: ëª¨ë“  ë°ì´í„° ìºì‹±)"
            )

            val_ratio = st.slider(
                "ê²€ì¦ ë°ì´í„° ë¹„ìœ¨",
                min_value=0.1,
                max_value=0.5,
                value=0.2,
                step=0.05,
                help="ê²€ì¦ ë°ì´í„°ë¡œ ì‚¬ìš©í•  ë¹„ìœ¨"
            )

            enable_cache = st.checkbox("ë°ì´í„° ìºì‹± í™œì„±í™”", value=True, help="í•™ìŠµ ì†ë„ í–¥ìƒì„ ìœ„í•œ ë°ì´í„° ìºì‹±")

            if st.button("ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì¤€ë¹„"):
                with st.spinner(f"{selected_dataset} ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        # ë””ë ‰í† ë¦¬ ìƒíƒœ í™•ì¸ ë° ì¶œë ¥
                        if not os.path.exists(dataset_root_dir):
                            st.info(f"'{dataset_root_dir}' ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                        
                        # ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
                        data_list, data_count, num_classes = download_monai_dataset(
                            selected_dataset, 
                            dataset_root_dir, 
                            cache_rate
                        )

                        # ë°ì´í„° ì •ë³´ ì €ì¥
                        st.session_state.training_data = data_list
                        st.session_state.val_ratio = val_ratio
                        st.session_state.num_classes = num_classes

                        # ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ë©”ì‹œì§€
                        st.success(f"{selected_dataset} ë°ì´í„°ì…‹ì„ ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤! ({len(data_list)}ê°œ ë°ì´í„°)")
                        
                    except Exception as e:
                        st.error(f"ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                        st.info("ë¬¸ì œ í•´ê²° íŒ:")
                        st.info("1. ì €ì¥ ê²½ë¡œì— ì“°ê¸° ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
                        st.info("2. ì¸í„°ë„· ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                        st.info("3. ì¼ë¶€ ë°ì´í„°ì…‹ì€ í¬ê¸°ê°€ í° ê²½ìš° ë‹¤ìš´ë¡œë“œì— ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        
                        # ë” ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´ í‘œì‹œ (ë””ë²„ê¹…ìš©)
                        with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
                            import traceback
                            st.code(traceback.format_exc())

                    
    # ìš°ì¸¡ ì»¬ëŸ¼ - í•™ìŠµ ì§„í–‰ ìƒí™© ë° ë°ì´í„° ì‹œê°í™”
    with col2:
        st.subheader("í•™ìŠµ ì§„í–‰ ìƒí™© ë° ë°ì´í„° ì‹œê°í™”")
        
        # í•™ìŠµ ì§„í–‰ ì¤‘ì¼ ë•Œ ì§„í–‰ ìƒíƒœ í‘œì‹œ
        if st.session_state.training_in_progress:
            if st.button("ëª¨ë¸ í•™ìŠµ ì‹œì‘"):
                # Streamlit UI ìš”ì†Œ ì¤€ë¹„
                progress_bar = st.progress(0)
                status_text = st.empty()
                metrics_container = st.container()

                async def update_progress(metrics):
                    progress = metrics['epoch'] / st.session_state.total_epochs
                    progress_bar.progress(progress)
                    status_text.text(f"ì—í¬í¬ {st.session_state.current_epoch}/{st.session_state.total_epochs} ì™„ë£Œ")
            
                    # í•™ìŠµ ì§€í‘œ í‘œì‹œ
                    with metrics_container:
                        col_loss, col_dice, col_lr = st.columns(3)
                        with col_loss:
                            st.metric("ì†ì‹¤ (Loss)", f"{metrics['loss']:.4f}")
                        with col_dice:
                            st.metric("Dice ì ìˆ˜", f"{metrics['dice']:.4f}")
                        with col_lr:
                            st.metric("í•™ìŠµë¥ ", f"{metrics['learning_rate']:.6f}")
                
                # ë¹„ë™ê¸° í•™ìŠµ ì‹¤í–‰
                asyncio.run(st.session_state.trainer.train( 
                    num_epochs=st.session_state.total_epochs,
                    progress_callback=update_progress
                ))

            # í•™ìŠµ ì§„í–‰ ìƒíƒœ ë° ì§€í‘œ ì—…ë°ì´íŠ¸
            # if st.session_state.current_epoch < st.session_state.total_epochs:
            #     try:
            #         # í•œ ì—í¬í¬ í•™ìŠµ ì§„í–‰
            #         metrics = st.session_state.trainer.train_epoch()
            #         st.session_state.current_epoch += 1
                    
            #         # ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
            #         progress.progress(st.session_state.current_epoch / st.session_state.total_epochs)
            #         status_text.text(f"ì—í¬í¬ {st.session_state.current_epoch}/{st.session_state.total_epochs} ì™„ë£Œ")
                    
            #         # í•™ìŠµ ì§€í‘œ í‘œì‹œ
            #         with metrics_container:
            #             col_loss, col_dice, col_lr = st.columns(3)
            #             with col_loss:
            #                 st.metric("ì†ì‹¤ (Loss)", f"{metrics['loss']:.4f}")
            #             with col_dice:
            #                 st.metric("Dice ì ìˆ˜", f"{metrics['dice']:.4f}")
            #             with col_lr:
            #                 st.metric("í•™ìŠµë¥ ", f"{metrics['learning_rate']:.6f}")
                        
            #             # ìƒ˜í”Œ ì´ë¯¸ì§€ ì‹œê°í™” (ìˆëŠ” ê²½ìš°)
            #             if 'sample_images' in metrics:
            #                 st.image(metrics['sample_images'], caption=["ì…ë ¥", "ì˜ˆì¸¡", "ì •ë‹µ"], width=150)
                    
            #         # ìë™ìœ¼ë¡œ ë‹¤ìŒ ì—í¬í¬ ì§„í–‰ì„ ìœ„í•œ ì¬ì‹¤í–‰
            #         if st.session_state.current_epoch < st.session_state.total_epochs:
            #             st.experimental_rerun()
            #         else:
            #             st.session_state.training_in_progress = False
            #             st.success("ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
            #             # ëª¨ë¸ ì €ì¥ ë²„íŠ¼ í‘œì‹œ
            #             if st.button("ëª¨ë¸ ì €ì¥"):
            #                 model_path = save_model(st.session_state.trainer)
            #                 st.success(f"ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {model_path}")
                
            #     except Exception as e:
            #         st.error(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            #         st.session_state.training_in_progress = False
        
        else:
            # í•™ìŠµ ì‹œì‘ ì „ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
            if 'training_data' in st.session_state:
                st.subheader("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
                preview_data = prepare_data_preview(
                    st.session_state.training_data,
                    max_samples=2
                )
                
                # ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
                # st.image(preview_data['images'][:3], 
                #          caption=preview_data['captions'][:3], 
                #          width=200)

                # ë°ì´í„° í†µê³„ í‘œì‹œ
                # st.write(f"ì´ ë°ì´í„° ìˆ˜: {preview_data['total_samples']}")
                # st.write(f"í´ë˜ìŠ¤ ë¶„í¬: {preview_data['class_distribution']}")
                
                for sample in preview_data["samples"]:
                    st.subheader(f"ìƒ˜í”Œ #{sample['index'] + 1}")
                    if "error" in sample:
                        st.error(f"ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜: {sample['error']}")

                        # ë” ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´ í‘œì‹œ (ë””ë²„ê¹…ìš©)
                        with st.expander("ìƒì„¸ ì˜¤ë¥˜ ì •ë³´"):
                            import traceback
                            st.code(traceback.format_exc())
                    else:
                        st.image(sample["preview_img"], caption="ì¤‘ì•™ ìŠ¬ë¼ì´ìŠ¤ ë¯¸ë¦¬ë³´ê¸°")

            else:
                st.info("ì™¼ìª½ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•œ í›„ í•™ìŠµì„ ì‹œì‘í•˜ì„¸ìš”.")

with tabs[1]:
    st.header("ì¶”ë¡  ë° ë¶„ì„")
    
    inference_col1, inference_col2 = st.columns([1, 2])
    
    with inference_col1:
        st.subheader("ì¶”ë¡  ì„¤ì •")
        
        # ëª¨ë¸ ì„ íƒ (í•™ìŠµëœ ëª¨ë¸ ë˜ëŠ” ì‚¬ì „í•™ìŠµ ëª¨ë¸)
        model_source = st.radio(
            "ëª¨ë¸ ì†ŒìŠ¤",
            ["ë°©ê¸ˆ í•™ìŠµí•œ ëª¨ë¸", "ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°", "ì‚¬ì „í•™ìŠµ ëª¨ë¸"]
        )
        
        if model_source == "ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°":
            model_path = st.text_input("ëª¨ë¸ íŒŒì¼ ê²½ë¡œ")
            
            if model_path and st.button("ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°"):
                with st.spinner("ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                    loaded_model = load_model(model_path)
                    st.session_state.inference_model = loaded_model
                    st.success("ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!")
        
        elif model_source == "ì‚¬ì „í•™ìŠµ ëª¨ë¸":
            pretrained_model = st.selectbox(
                "ì‚¬ì „í•™ìŠµ ëª¨ë¸ ì„ íƒ",
                ["swin_unetr.segresnet_btcv", "unet_btcv", "segresnet_btcv"]
            )
            
            if st.button("ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°"):
                with st.spinner("ì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                    pretrained = load_pretrained_model(pretrained_model)
                    st.session_state.inference_model = pretrained
                    st.success("ì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!")
        
        # ì¶”ë¡ í•  ì´ë¯¸ì§€ ì—…ë¡œë“œ
        uploaded_image = st.file_uploader(
            "ë¶„ì„í•  ì˜ë£Œ ì˜ìƒ ì—…ë¡œë“œ",
            type=["nii.gz", "nii", "dcm", "png", "jpg"]
        )
        
        # í›„ì²˜ë¦¬ ì˜µì…˜
        st.subheader("í›„ì²˜ë¦¬ ì˜µì…˜")
        post_process = st.checkbox("ë¶„í•  ê²°ê³¼ í›„ì²˜ë¦¬", value=True)
        
        if post_process:
            smoothing = st.slider(
                "ê²½ê³„ ìŠ¤ë¬´ë”© ì •ë„",
                min_value=0.0,
                max_value=1.0,
                value=0.3,
                step=0.1
            )
            
            min_region_size = st.number_input(
                "ìµœì†Œ ì˜ì—­ í¬ê¸° (ë³µì…€)",
                min_value=10,
                max_value=1000,
                value=100
            )
        
        # ì¶”ë¡  ì‹¤í–‰ ë²„íŠ¼
        if st.button("ì˜ìƒ ë¶„ì„ ì‹¤í–‰"):
            if uploaded_image is None:
                st.error("ë¶„ì„í•  ì˜ìƒì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            elif 'inference_model' not in st.session_state and model_source != "ë°©ê¸ˆ í•™ìŠµí•œ ëª¨ë¸":
                st.error("ë¨¼ì € ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ì˜ìƒì„ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                    if model_source == "ë°©ê¸ˆ í•™ìŠµí•œ ëª¨ë¸":
                        if 'trainer' not in st.session_state:
                            st.error("í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•´ì£¼ì„¸ìš”.")
                        else:
                            model = st.session_state.trainer.get_model()
                    else:
                        model = st.session_state.inference_model
                    
                    # ì˜ìƒ ì²˜ë¦¬ ë° ì¶”ë¡ 
                    result = run_inference(
                        model=model,
                        image=uploaded_image,
                        post_process=post_process,
                        smoothing=smoothing if post_process else 0.0,
                        min_region_size=min_region_size if post_process else 0
                    )
                    
                    st.session_state.inference_result = result
                    st.success("ì˜ìƒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    with inference_col2:
        st.subheader("ë¶„ì„ ê²°ê³¼")
        
        if 'inference_result' in st.session_state:
            result = st.session_state.inference_result
            
            # ê²°ê³¼ ì‹œê°í™” ì„ íƒ
            view_mode = st.radio(
                "ê²°ê³¼ ë³´ê¸° ëª¨ë“œ",
                ["2D ìŠ¬ë¼ì´ìŠ¤", "3D ë Œë”ë§", "ì˜¤ë²„ë ˆì´"]
            )
            
            if view_mode == "2D ìŠ¬ë¼ì´ìŠ¤":
                # ìŠ¬ë¼ì´ìŠ¤ ì„ íƒê¸°
                if result['is_3d']:
                    axis = st.selectbox("í‘œì‹œ ì¶•", ["Axial", "Coronal", "Sagittal"])
                    slice_idx = st.slider(
                        "ìŠ¬ë¼ì´ìŠ¤ ì„ íƒ",
                        min_value=0,
                        max_value=result['dims'][{"Axial": 0, "Coronal": 1, "Sagittal": 2}[axis]],
                        value=result['dims'][{"Axial": 0, "Coronal": 1, "Sagittal": 2}[axis]]//2
                    )
                    
                    # ì„ íƒëœ ìŠ¬ë¼ì´ìŠ¤ í‘œì‹œ
                    slice_viewer = display_slice(
                        result['original'],
                        result['segmentation'],
                        axis={"Axial": 0, "Coronal": 1, "Sagittal": 2}[axis],
                        slice_idx=slice_idx
                    )
                    st.image(slice_viewer, use_column_width=True)
                else:
                    # 2D ì´ë¯¸ì§€ ê²°ê³¼ í‘œì‹œ
                    st.image([result['original'], result['segmentation']], 
                             caption=["ì›ë³¸ ì´ë¯¸ì§€", "ë¶„í•  ê²°ê³¼"],
                             width=300)
            
            elif view_mode == "3D ë Œë”ë§":
                if result['is_3d']:
                    # 3D ë Œë”ë§ ì˜µì…˜
                    opacity = st.slider("íˆ¬ëª…ë„", min_value=0.1, max_value=1.0, value=0.7, step=0.1)
                    
                    # 3D ë Œë”ë§ í‘œì‹œ
                    render_3d(result['segmentation'], opacity=opacity)
                else:
                    st.warning("3D ë Œë”ë§ì€ 3D ë³¼ë¥¨ ë°ì´í„°ì—ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            elif view_mode == "ì˜¤ë²„ë ˆì´":
                # ì˜¤ë²„ë ˆì´ ì˜µì…˜
                overlay_opacity = st.slider("ì˜¤ë²„ë ˆì´ íˆ¬ëª…ë„", min_value=0.1, max_value=1.0, value=0.5, step=0.1)
                
                if result['is_3d']:
                    axis = st.selectbox("ì˜¤ë²„ë ˆì´ ì¶•", ["Axial", "Coronal", "Sagittal"])
                    overlay_slice_idx = st.slider(
                        "ì˜¤ë²„ë ˆì´ ìŠ¬ë¼ì´ìŠ¤",
                        min_value=0,
                        max_value=result['dims'][{"Axial": 0, "Coronal": 1, "Sagittal": 2}[axis]],
                        value=result['dims'][{"Axial": 0, "Coronal": 1, "Sagittal": 2}[axis]]//2
                    )
                    
                    # ì˜¤ë²„ë ˆì´ í‘œì‹œ
                    overlay_viewer = display_overlay(
                        result['original'],
                        result['segmentation'],
                        axis={"Axial": 0, "Coronal": 1, "Sagittal": 2}[axis],
                        slice_idx=overlay_slice_idx,
                        opacity=overlay_opacity
                    )
                    st.image(overlay_viewer, use_column_width=True)
                else:
                    # 2D ì´ë¯¸ì§€ ì˜¤ë²„ë ˆì´ í‘œì‹œ
                    overlay_image = create_overlay(
                        result['original'], 
                        result['segmentation'],
                        opacity=overlay_opacity
                    )
                    st.image(overlay_image, caption="ë¶„í•  ì˜¤ë²„ë ˆì´", use_column_width=True)
            
            # ë¶„ì„ ì§€í‘œ
            st.subheader("ë¶„ì„ ì§€í‘œ")
            metrics_col1, metrics_col2 = st.columns(2)
            
            with metrics_col1:
                for idx, metric in enumerate(result['metrics'][:len(result['metrics'])//2]):
                    st.metric(metric['name'], metric['value'], delta=metric.get('delta'))
            
            with metrics_col2:
                for idx, metric in enumerate(result['metrics'][len(result['metrics'])//2:]):
                    st.metric(metric['name'], metric['value'], delta=metric.get('delta'))
            
            # ê²°ê³¼ ë‚´ë³´ë‚´ê¸°
            st.subheader("ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")
            export_format = st.selectbox(
                "ë‚´ë³´ë‚´ê¸° í˜•ì‹",
                ["NIfTI (.nii.gz)", "DICOM (.dcm)", "PNG ì‹œë¦¬ì¦ˆ"]
            )
            
            if st.button("ê²°ê³¼ ë‚´ë³´ë‚´ê¸°"):
                with st.spinner("ê²°ê³¼ë¥¼ ë‚´ë³´ë‚´ëŠ” ì¤‘..."):
                    export_path = export_results(
                        result,
                        format=export_format
                    )
                    st.success(f"ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {export_path}")
                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    with open(export_path, "rb") as file:
                        st.download_button(
                            label="ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                            data=file,
                            file_name=os.path.basename(export_path),
                            mime="application/octet-stream"
                        )
        
        else:
            st.info("ì˜ìƒì„ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ì„ ì‹¤í–‰í•˜ë©´ ì—¬ê¸°ì— ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

with tabs[2]:
    st.header("í•™ìŠµ ìë£Œ")
    
    material_type = st.radio(
        "ìë£Œ ìœ í˜•",
        ["íŠœí† ë¦¬ì–¼", "ì´ë¡  ì„¤ëª…", "ë…¼ë¬¸ ë° ì°¸ê³ ìë£Œ"]
    )
    
    if material_type == "íŠœí† ë¦¬ì–¼":
        st.subheader("ì˜ë£Œ ì˜ìƒ ë¶„í•  ëª¨ë¸ í•™ìŠµ íŠœí† ë¦¬ì–¼")
        
        tutorial_steps = [
            "1. ë°ì´í„° ì¤€ë¹„",
            "2. ëª¨ë¸ ì„ íƒ ë° ì„¤ì •",
            "3. í•™ìŠµ ê³¼ì •",
            "4. ëª¨ë¸ í‰ê°€",
            "5. ì¶”ë¡  ë° í™œìš©"
        ]
        
        selected_step = st.selectbox("íŠœí† ë¦¬ì–¼ ë‹¨ê³„", tutorial_steps)
        
        # ì„ íƒëœ íŠœí† ë¦¬ì–¼ ë‹¨ê³„ì— ë”°ë¥¸ ë‚´ìš© í‘œì‹œ
        if selected_step == "1. ë°ì´í„° ì¤€ë¹„":
            st.write("""
            ### ë°ì´í„° ì¤€ë¹„ ë‹¨ê³„
            
            ì˜ë£Œ ì˜ìƒ ë¶„í• ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„ ê³¼ì •ì—ì„œ ê³ ë ¤í•´ì•¼ í•  ì‚¬í•­:
            
            1. **ë°ì´í„° í¬ë§·**: NIfTI, DICOM ë“±ì˜ ì˜ë£Œ ì˜ìƒ í¬ë§·ì„ ì ì ˆíˆ ë¶ˆëŸ¬ì˜¤ê³  ì²˜ë¦¬í•˜ëŠ” ë°©ë²•
            2. **ë°ì´í„° ì „ì²˜ë¦¬**: ì •ê·œí™”, ë¦¬ìƒ˜í”Œë§, í¬ë¡­ ë“±ì˜ ì „ì²˜ë¦¬ ê¸°ë²•
            3. **ë°ì´í„° ì¦ê°•**: íšŒì „, í”Œë¦½, ëª…ì•” ì¡°ì • ë“±ì„ í†µí•œ ë°ì´í„° ì¦ê°• ë°©ë²•
            4. **ë°ì´í„°ì…‹ ë¶„í• **: í•™ìŠµ, ê²€ì¦, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì˜ ì ì ˆí•œ ë¶„í•  ë°©ë²•
            """)
            
            # ì˜ˆì œ ì½”ë“œ
            st.code("""
            # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì˜ˆì œ
            import monai
            from monai.transforms import (
                Compose, LoadImaged, AddChanneld, ScaleIntensityd,
                RandRotated, RandZoomd, RandFlipd, ToTensord
            )
            
            # ë°ì´í„° ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì •ì˜
            train_transforms = Compose([
                LoadImaged(keys=["image", "label"]),
                AddChanneld(keys=["image", "label"]),
                ScaleIntensityd(keys=["image"]),
                RandRotated(keys=["image", "label"], prob=0.5, range_x=0.3),
                RandZoomd(keys=["image", "label"], prob=0.5, min_zoom=0.8, max_zoom=1.2),
                RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=0),
                ToTensord(keys=["image", "label"])
            ])
            
            # ë°ì´í„° ë¡œë” ìƒì„±
            train_ds = monai.data.CacheDataset(
                data=train_files, transform=train_transforms, cache_rate=1.0
            )
            train_loader = monai.data.DataLoader(
                train_ds, batch_size=2, shuffle=True, num_workers=4
            )
            """, language="python")
            
        elif selected_step == "2. ëª¨ë¸ ì„ íƒ ë° ì„¤ì •":
            st.write("""
            ### ëª¨ë¸ ì„ íƒ ë° ì„¤ì •
            
            ì˜ë£Œ ì˜ìƒ ë¶„í• ì„ ìœ„í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì„ íƒê³¼ êµ¬ì„±:
            
            1. **ëª¨ë¸ ì•„í‚¤í…ì²˜**: U-Net, SegResNet, SwinUNETR ë“± ì˜ë£Œ ì˜ìƒ ë¶„í• ì— ì í•©í•œ ì•„í‚¤í…ì²˜ ì„ íƒ
            2. **í•˜ì´í¼íŒŒë¼ë¯¸í„°**: ë°°ì¹˜ í¬ê¸°, í•™ìŠµë¥ , ì˜µí‹°ë§ˆì´ì € ë“±ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
            3. **ì†ì‹¤ í•¨ìˆ˜**: Dice Loss, Focal Loss ë“± ì˜ë£Œ ì˜ìƒ ë¶„í• ì— ì í•©í•œ ì†ì‹¤ í•¨ìˆ˜ ì„ íƒ
            4. **í‰ê°€ ì§€í‘œ**: Dice ê³„ìˆ˜, Hausdorff ê±°ë¦¬ ë“±ì˜ ì„±ëŠ¥ í‰ê°€ ì§€í‘œ
            """)
            
            # ì˜ˆì œ ì½”ë“œ
            st.code("""
            # ëª¨ë¸ ì´ˆê¸°í™” ì˜ˆì œ
            from monai.networks.nets import UNet, SegResNet, SwinUNETR
            from monai.losses import DiceLoss
            import torch
            
            # ëª¨ë¸ ì„ íƒ ë° ì´ˆê¸°í™”
            model = UNet(
                dimensions=3,
                in_channels=1,
                out_channels=2,  # ë°°ê²½ + ë¶„í•  í´ë˜ìŠ¤
                channels=(16, 32, 64, 128, 256),
                strides=(2, 2, 2, 2),
                num_res_units=2,
            )
            
            # ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
            loss_function = DiceLoss(to_onehot_y=True, softmax=True)
            optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
            
            # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
                optimizer, 'min', factor=0.5, patience=5
            )
            """, language="python")
            
        elif selected_step == "3. í•™ìŠµ ê³¼ì •":
            st.write("""
            ### í•™ìŠµ ê³¼ì •
            
            ì˜ë£Œ ì˜ìƒ ë¶„í•  ëª¨ë¸ì˜ íš¨ê³¼ì ì¸ í•™ìŠµì„ ìœ„í•œ íŒ:
            
            1. **ë°°ì¹˜ ì •ê·œí™”**: í•™ìŠµ ì•ˆì •ì„±ì„ ìœ„í•œ ë°°ì¹˜ ì •ê·œí™” ì‚¬ìš©
            2. **ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘**: ê·¸ë˜ë””ì–¸íŠ¸ í­ë°œ ë°©ì§€ë¥¼ ìœ„í•œ í´ë¦¬í•‘
            3. **ì¡°ê¸° ì¢…ë£Œ**: ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ì¡°ê¸° ì¢…ë£Œ ì „ëµ
            4. **í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§**: íš¨ê³¼ì ì¸ í•™ìŠµì„ ìœ„í•œ í•™ìŠµë¥  ì¡°ì •
            5. **ê²€ì¦ ëª¨ë‹ˆí„°ë§**: í•™ìŠµ ì¤‘ ê²€ì¦ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            """)
            
            # ì˜ˆì œ ì½”ë“œ
            st.code("""
            # í•™ìŠµ ë£¨í”„ ì˜ˆì œ
            from monai.engines import SupervisedTrainer
            from monai.handlers import (
                StatsHandler, TensorBoardStatsHandler, 
                CheckpointSaver, LrScheduleHandler
            )
            
            # í•™ìŠµ ì—”ì§„ ì„¤ì •
            trainer = SupervisedTrainer(
                device=device,
                max_epochs=50,
                train_data_loader=train_loader,
                network=model,
                optimizer=optimizer,
                loss_function=loss_function,
                inferer=SimpleInferer(),
                key_train_metric={"train_dice": MeanDice(include_background=False)},
                train_handlers=[
                    LrScheduleHandler(
                        lr_scheduler=scheduler,
                        print_lr=True
                    ),
                    StatsHandler(
                        tag_name="train_loss",
                        output_transform=lambda x: x["loss"]
                    ),
                    TensorBoardStatsHandler(
                        log_dir="./runs",
                        tag_name="train_loss",
                        output_transform=lambda x: x["loss"]
                    ),
                    CheckpointSaver(
                        save_dir="./checkpoints",
                        save_dict={"model": model, "optimizer": optimizer},
                        save_interval=5
                    )
                ]
            )
            
            # í•™ìŠµ ì‹¤í–‰
            trainer.run()
            """, language="python")
            
        elif selected_step == "4. ëª¨ë¸ í‰ê°€":
            st.write("""
            ### ëª¨ë¸ í‰ê°€
            
            ì˜ë£Œ ì˜ìƒ ë¶„í•  ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€ ë°©ë²•:
            
            1. **êµì°¨ ê²€ì¦**: ëª¨ë¸ ì•ˆì •ì„± í‰ê°€ë¥¼ ìœ„í•œ êµì°¨ ê²€ì¦
            2. **í‰ê°€ ì§€í‘œ**: Dice, Jaccard, Hausdorff ê±°ë¦¬ ë“±ì˜ í‰ê°€ ì§€í‘œ
            3. **í˜¼ë™ í–‰ë ¬**: í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„ì„ ìœ„í•œ í˜¼ë™ í–‰ë ¬
            4. **ì‹œê°í™”**: ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ ë§ˆìŠ¤í¬ì˜ ì‹œê°ì  ë¹„êµ
            5. **í†µê³„ ë¶„ì„**: í‰ê°€ ê²°ê³¼ì˜ í†µê³„ì  ë¶„ì„
            """)
            
            # ì˜ˆì œ ì½”ë“œ
            st.code("""
            # ëª¨ë¸ í‰ê°€ ì˜ˆì œ
            from monai.engines import SupervisedEvaluator
            from monai.handlers import StatsHandler, CheckpointLoader
            from monai.metrics import DiceMetric, HausdorffDistanceMetric
            
            # í‰ê°€ ì§€í‘œ ì„¤ì •
            dice_metric = DiceMetric(include_background=False)
            hausdorff_metric = HausdorffDistanceMetric(include_background=False)
            
            # í‰ê°€ ì—”ì§„ ì„¤ì •
            evaluator = SupervisedEvaluator(
                device=device,
                val_data_loader=val_loader,
                network=model,
                inferer=SimpleInferer(),
                key_val_metric={
                    "val_dice": dice_metric,
                    "val_hausdorff": hausdorff_metric
                },
                val_handlers=[
                    StatsHandler(
                        output_transform=lambda x: None
                    ),
                    CheckpointLoader(
                        load_path="./checkpoints/best_model.pt",
                        load_dict={"model": model}
                    )
                ]
            )
            
            # í‰ê°€ ì‹¤í–‰
            evaluator.run()
            
            # ê²°ê³¼ ì¶œë ¥
            metrics = evaluator.state.metrics
            print(f"Dice: {metrics['val_dice']:.4f}")
            print(f"Hausdorff: {metrics['val_hausdorff']:.4f}")
            """, language="python")
            
        elif selected_step == "5. ì¶”ë¡  ë° í™œìš©":
            st.write("""
            ### ì¶”ë¡  ë° í™œìš©
            
            í•™ìŠµëœ ì˜ë£Œ ì˜ìƒ ë¶„í•  ëª¨ë¸ì˜ í™œìš© ë°©ë²•:
            
            1. **ë‹¨ì¼ ì˜ìƒ ì¶”ë¡ **: ìƒˆë¡œìš´ ì˜ìƒì— ëŒ€í•œ ë¶„í•  ì˜ˆì¸¡
            2. **ë°°ì¹˜ ì²˜ë¦¬**: ë‹¤ìˆ˜ì˜ ì˜ìƒì„ í•œë²ˆì— ì²˜ë¦¬
            3. **ì„ìƒ í™˜ê²½ í™œìš©**: ì‹¤ì œ ì§„ë£Œ í™˜ê²½ì—ì„œì˜ ì ìš© ë°©ë²•
            4. **ê²°ê³¼ ì‹œê°í™”**: ë¶„í•  ê²°ê³¼ì˜ íš¨ê³¼ì ì¸ ì‹œê°í™” ë°©ë²•
            """)
            
            st.markdown("#### ì¶”ë¡  ì½”ë“œ ì˜ˆì‹œ")
            
            code = '''
            # ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
            model = UNet(in_channels=1, out_channels=num_classes).to(device)
            model.load_state_dict(torch.load('best_model.pth'))
            model.eval()
            
            # ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ 
            with torch.no_grad():
                image = load_and_preprocess_image('new_image.png')
                image_tensor = torch.from_numpy(image).unsqueeze(0).to(device)
                prediction = model(image_tensor)
                segmentation_mask = torch.argmax(prediction, dim=1).squeeze().cpu().numpy()
                
            # ê²°ê³¼ ì‹œê°í™”
            plt.figure(figsize=(12, 5))
            plt.subplot(1, 2, 1)
            plt.imshow(image.squeeze(), cmap='gray')
            plt.title('ì›ë³¸ ì˜ìƒ')
            
            plt.subplot(1, 2, 2)
            plt.imshow(segmentation_mask, cmap='viridis')
            plt.title('ë¶„í•  ê²°ê³¼')
            plt.colorbar()
            plt.tight_layout()
            plt.savefig('segmentation_result.png')
            plt.show()
            '''
            
            st.code(code, language='python')
            
            st.markdown("#### ì„ìƒ í™œìš© ë°©ë²•")
            st.write("""
            - ì˜ìƒ ë¶„í•  ê²°ê³¼ë¥¼ DICOM í¬ë§·ìœ¼ë¡œ ì €ì¥í•˜ì—¬ PACS ì‹œìŠ¤í…œê³¼ í†µí•©
            - ë¶„í• ëœ ì˜ì—­ì˜ ì²´ì  ê³„ì‚°ì„ í†µí•œ ì •ëŸ‰ì  ë¶„ì„ ì œê³µ
            - ì¢…ë‹¨ì  ì—°êµ¬ë¥¼ ìœ„í•œ ì´ì „ ê²€ì‚¬ì™€ì˜ ë¹„êµ ê¸°ëŠ¥ êµ¬í˜„
            - ë‹¤ì–‘í•œ ì¥ê¸°/ë³‘ë³€ ìœ í˜•ì— ëŒ€í•œ ì•™ìƒë¸” ëª¨ë¸ êµ¬ì¶•
            """)
            
            st.warning("ì£¼ì˜: ì„ìƒ í™˜ê²½ì—ì„œ ì‚¬ìš©í•˜ê¸° ì „ì— ë°˜ë“œì‹œ ì˜ë£Œê¸°ê¸° ì¸ì¦ ë° ì„ìƒ ê²€ì¦ ê³¼ì •ì„ ê±°ì³ì•¼ í•©ë‹ˆë‹¤.")

    elif material_type == "ì´ë¡  ì„¤ëª…":
        st.subheader("ì˜ë£Œ ì˜ìƒ ë¶„í•  ì´ë¡ ")
        
        theory_topics = [
            "ì˜ë£Œ ì˜ìƒ ë¶„í•  ê°œìš”",
            "ì „í†µì  ë¶„í•  ê¸°ë²•",
            "ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë¶„í•  ê¸°ë²•",
            "í‰ê°€ ì§€í‘œì™€ ê²€ì¦ ë°©ë²•"
        ]
        
        selected_theory = st.selectbox("ì´ë¡  ì£¼ì œ", theory_topics)
        
        if selected_theory == "ì˜ë£Œ ì˜ìƒ ë¶„í•  ê°œìš”":
            st.write("""
            ### ì˜ë£Œ ì˜ìƒ ë¶„í•  ê°œìš”
            
            ì˜ë£Œ ì˜ìƒ ë¶„í• (Medical Image Segmentation)ì€ ì˜ë£Œ ì˜ìƒì—ì„œ ê´€ì‹¬ ì˜ì—­(ROI)ì„ ì‹ë³„í•˜ê³  ë¶„ë¦¬í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. 
            ì´ëŠ” ì§„ë‹¨, ìˆ˜ìˆ  ê³„íš, ì¹˜ë£Œ ëª¨ë‹ˆí„°ë§ ë“± ë‹¤ì–‘í•œ ì„ìƒ ì‘ìš© ë¶„ì•¼ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.
            
            #### ì˜ë£Œ ì˜ìƒ ë¶„í• ì˜ ì¤‘ìš”ì„±
            
            - **ì •í™•í•œ ì§„ë‹¨**: ì •ë°€í•œ ë¶„í• ì„ í†µí•´ ë³‘ë³€ì˜ í¬ê¸°, ìœ„ì¹˜, í˜•íƒœì— ëŒ€í•œ ì •í™•í•œ ì •ë³´ ì œê³µ
            - **ìˆ˜ìˆ  ê³„íš**: ì¤‘ìš” êµ¬ì¡°ë¬¼ê³¼ ë³‘ë³€ì˜ 3D ì‹œê°í™”ë¥¼ í†µí•œ ìˆ˜ìˆ  ì „ ê³„íš ìˆ˜ë¦½
            - **ë°©ì‚¬ì„  ì¹˜ë£Œ**: ì •í™•í•œ íƒ€ê²Ÿ ì˜ì—­ ì •ì˜ë¥¼ í†µí•œ ë°©ì‚¬ì„  ì¹˜ë£Œ ìµœì í™”
            - **ì •ëŸ‰ì  ë¶„ì„**: ì¥ê¸° ë¶€í”¼, ë³‘ë³€ í¬ê¸° ë³€í™” ë“±ì˜ ì •ëŸ‰ì  ì¸¡ì • ê°€ëŠ¥
            - **ì»´í“¨í„° ë³´ì¡° ì§„ë‹¨**: ìë™í™”ëœ ì§„ë‹¨ ì§€ì› ì‹œìŠ¤í…œ ê°œë°œì˜ ê¸°ë°˜
            
            #### ì˜ë£Œ ì˜ìƒ ë¶„í• ì˜ ë„ì „ ê³¼ì œ
            
            - **ì˜ìƒ í’ˆì§ˆ**: ë…¸ì´ì¦ˆ, ì•„í‹°íŒ©íŠ¸, ì €ëŒ€ë¹„ ë“±ì˜ ì˜ìƒ í’ˆì§ˆ ë¬¸ì œ
            - **í•´ë¶€í•™ì  ë³€ì´**: í™˜ìë§ˆë‹¤ ë‹¤ë¥¸ í•´ë¶€í•™ì  êµ¬ì¡° ë° ë³‘ë¦¬í•™ì  ë³€ì´
            - **ê²½ê³„ ëª¨í˜¸ì„±**: ì¸ì ‘ ì¡°ì§ê³¼ì˜ ë¶ˆëª…í™•í•œ ê²½ê³„
            - **ë°ì´í„° í¬ì†Œì„±**: ë ˆì´ë¸”ë§ëœ ì˜ë£Œ ë°ì´í„°ì˜ ë¶€ì¡±
            - **ì „ë¬¸ ì§€ì‹ ìš”êµ¬**: ì •í™•í•œ ë¶„í• ì„ ìœ„í•œ ì˜í•™ì  ì „ë¬¸ ì§€ì‹ í•„ìš”
            """)
        
        elif selected_theory == "ì „í†µì  ë¶„í•  ê¸°ë²•":
            st.write("""
            ### ì „í†µì  ë¶„í•  ê¸°ë²•
            
            ë”¥ëŸ¬ë‹ ì´ì „ì— ì‚¬ìš©ë˜ë˜ ì „í†µì ì¸ ì˜ë£Œ ì˜ìƒ ë¶„í•  ê¸°ë²•ë“¤ì€ ì—¬ì „íˆ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.
            
            #### ì„ê³„ê°’ ê¸°ë°˜ ê¸°ë²•
            
            - **ì „ì—­ ì„ê³„ê°’**: ë‹¨ì¼ ì„ê³„ê°’ì„ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ì˜ìƒì— ì ìš©
            - **ì§€ì—­ ì„ê³„ê°’**: ì˜ì—­ë³„ë¡œ ë‹¤ë¥¸ ì„ê³„ê°’ ì ìš©
            - **Otsu ë°©ë²•**: í´ë˜ìŠ¤ ë‚´ ë¶„ì‚°ì„ ìµœì†Œí™”í•˜ëŠ” ìµœì ì˜ ì„ê³„ê°’ ìë™ ê³„ì‚°
            
            #### ì˜ì—­ ê¸°ë°˜ ê¸°ë²•
            
            - **ì˜ì—­ ì„±ì¥ë²•(Region Growing)**: ì‹œë“œ í¬ì¸íŠ¸ë¡œë¶€í„° ìœ ì‚¬í•œ íŠ¹ì„±ì„ ê°€ì§„ ì´ì›ƒ í”½ì…€ì„ í†µí•©
            - **ì›Œí„°ì‰ë“œ(Watershed)**: ì§€í˜•í•™ì  ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì˜ì—­ ê²½ê³„ ì‹ë³„
            - **ê·¸ë˜í”„ ì»·(Graph Cut)**: ì—ë„ˆì§€ í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” ìµœì  ë¶„í•  ê³„ì‚°
            
            #### ê²½ê³„ ê¸°ë°˜ ê¸°ë²•
            
            - **ê²½ê³„ ê²€ì¶œê¸°(Edge Detectors)**: Sobel, Canny ë“±ì˜ í•„í„°ë¥¼ ì‚¬ìš©í•œ ê²½ê³„ ê²€ì¶œ
            - **ì•¡í‹°ë¸Œ ì»¨íˆ¬ì–´(Active Contours/Snakes)**: ì—ë„ˆì§€ë¥¼ ìµœì†Œí™”í•˜ë©° ê²½ê³„ì— ë§ê²Œ ë³€í˜•ë˜ëŠ” ê³¡ì„ 
            - **ë ˆë²¨ ì…‹(Level Sets)**: ê³ ì°¨ì› í•¨ìˆ˜ì˜ ì˜ì  ì§‘í•©ìœ¼ë¡œ ê²½ê³„ í‘œí˜„
            
            #### ì•„í‹€ë¼ìŠ¤ ê¸°ë°˜ ê¸°ë²•
            
            - **ë‹¨ì¼ ì•„í‹€ë¼ìŠ¤**: í‘œì¤€ í…œí”Œë¦¿ì„ ëŒ€ìƒ ì˜ìƒì— ì •í•©(registration)
            - **ë‹¤ì¤‘ ì•„í‹€ë¼ìŠ¤**: ì—¬ëŸ¬ í…œí”Œë¦¿ì„ ì •í•©í•œ í›„ ê²°ê³¼ ìœµí•©
            - **í™•ë¥ ì  ì•„í‹€ë¼ìŠ¤**: í•´ë¶€í•™ì  êµ¬ì¡°ì˜ í†µê³„ì  ë³€ì´ ëª¨ë¸ë§
            """)
            
            st.image("https://via.placeholder.com/600x300.png?text=Traditional+Segmentation+Methods", 
                    caption="ì „í†µì  ë¶„í•  ê¸°ë²•ì˜ ì˜ˆì‹œ (ì´ë¯¸ì§€ëŠ” ì‹¤ì œ êµ¬í˜„ ì‹œ ê´€ë ¨ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´)")
        
        elif selected_theory == "ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë¶„í•  ê¸°ë²•":
            st.write("""
            ### ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë¶„í•  ê¸°ë²•
            
            ìµœê·¼ ë”¥ëŸ¬ë‹ ê¸°ìˆ ì˜ ë°œì „ìœ¼ë¡œ ì˜ë£Œ ì˜ìƒ ë¶„í•  ì„±ëŠ¥ì´ ë¹„ì•½ì ìœ¼ë¡œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.
            
            #### CNN ê¸°ë°˜ ë¶„í•  ì•„í‚¤í…ì²˜
            
            - **U-Net**: ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ì™€ ìŠ¤í‚µ ì—°ê²°ì„ í™œìš©í•œ ì˜ë£Œ ì˜ìƒ ë¶„í• ì˜ ëŒ€í‘œì  ì•„í‚¤í…ì²˜
            - **V-Net**: 3D ë³¼ë¥¨ ë°ì´í„°ë¥¼ ì§ì ‘ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ U-Netì˜ 3D í™•ì¥ ë²„ì „
            - **SegNet**: ì¸ì½”ë”ì˜ í’€ë§ ì¸ë±ìŠ¤ë¥¼ ë””ì½”ë”ì— ì „ë‹¬í•˜ëŠ” êµ¬ì¡°
            - **DeepLab**: í™•ì¥ í•©ì„±ê³±(Dilated Convolution)ê³¼ ê³µê°„ í”¼ë¼ë¯¸ë“œ í’€ë§ì„ í™œìš©
            
            #### íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ë¶„í•  ì•„í‚¤í…ì²˜
            
            - **UNETR**: U-Netê³¼ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ê²°í•©í•œ êµ¬ì¡°
            - **SwinUNETR**: Swin íŠ¸ëœìŠ¤í¬ë¨¸ ë¸”ë¡ì„ í™œìš©í•œ U-Net êµ¬ì¡°
            - **TransUNet**: CNNê³¼ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì¥ì ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸
            
            #### ì£¼ìš” ê¸°ìˆ  ìš”ì†Œ
            
            - **ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜**: ì¤‘ìš” íŠ¹ì§•ì— ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” ì–´í…ì…˜ ëª¨ë“ˆ
            - **ë©€í‹°ìŠ¤ì¼€ì¼ ì²˜ë¦¬**: ë‹¤ì–‘í•œ í¬ê¸°ì˜ ê°ì²´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬
            - **ì•½ì§€ë„ í•™ìŠµ**: ì ì€ ë ˆì´ë¸” ë°ì´í„°ë¡œë„ í•™ìŠµ ê°€ëŠ¥í•œ ê¸°ë²•
            - **ë„ë©”ì¸ ì ì‘**: ì„œë¡œ ë‹¤ë¥¸ ìŠ¤ìºë„ˆë‚˜ í”„ë¡œí† ì½œ ê°„ì˜ ê²©ì°¨ í•´ì†Œ
            
            #### ì†ì‹¤ í•¨ìˆ˜
            
            - **Dice Loss**: í´ë˜ìŠ¤ ë¶ˆê· í˜•ì— ê°•ê±´í•œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ì†ì‹¤ í•¨ìˆ˜
            - **Focal Loss**: ì–´ë ¤ìš´ ìƒ˜í”Œì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬
            - **Boundary Loss**: ê°ì²´ ê²½ê³„ì— ì§‘ì¤‘í•˜ëŠ” ì†ì‹¤ í•¨ìˆ˜
            - **Compound Loss**: ì—¬ëŸ¬ ì†ì‹¤ í•¨ìˆ˜ì˜ ì¡°í•©(ì˜ˆ: Dice + Cross Entropy)
            """)
            
            st.image("https://via.placeholder.com/600x300.png?text=Deep+Learning+Segmentation+Architectures", 
                    caption="ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë¶„í•  ì•„í‚¤í…ì²˜ (ì´ë¯¸ì§€ëŠ” ì‹¤ì œ êµ¬í˜„ ì‹œ ê´€ë ¨ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´)")
        
        elif selected_theory == "í‰ê°€ ì§€í‘œì™€ ê²€ì¦ ë°©ë²•":
            st.write("""
            ### í‰ê°€ ì§€í‘œì™€ ê²€ì¦ ë°©ë²•
            
            ì˜ë£Œ ì˜ìƒ ë¶„í•  ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì •í™•í•˜ê²Œ í‰ê°€í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ì§€í‘œì™€ ë°©ë²•ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
            
            #### ë¶„í•  ì„±ëŠ¥ í‰ê°€ ì§€í‘œ
            
            - **Dice ìœ ì‚¬ ê³„ìˆ˜(DSC)**: ì˜ˆì¸¡ê³¼ ì‹¤ì œ ë§ˆìŠ¤í¬ ê°„ì˜ ì¤‘ì²© ì •ë„ë¥¼ ì¸¡ì •
                - $DSC = \\frac{2|X \\cap Y|}{|X| + |Y|}$
            
            - **Jaccard ì¸ë±ìŠ¤(IoU)**: í•©ì§‘í•© ëŒ€ë¹„ êµì§‘í•©ì˜ ë¹„ìœ¨
                - $IoU = \\frac{|X \\cap Y|}{|X \\cup Y|}$
            
            - **Hausdorff ê±°ë¦¬**: ë‘ ì  ì§‘í•© ê°„ì˜ ìµœëŒ€ ê±°ë¦¬ë¥¼ ì¸¡ì •
                - $HD(X,Y) = \\max\\{\\sup_{x \\in X} \\inf_{y \\in Y} d(x,y), \\sup_{y \\in Y} \\inf_{x \\in X} d(y,x)\\}$
            
            - **ë¯¼ê°ë„ì™€ íŠ¹ì´ë„**: ì§„ì–‘ì„±ë¥ ê³¼ ì§„ìŒì„±ë¥ ì„ ì¸¡ì •
                - ë¯¼ê°ë„(Sensitivity) = $\\frac{TP}{TP+FN}$
                - íŠ¹ì´ë„(Specificity) = $\\frac{TN}{TN+FP}$
            
            - **ì²´ì  ìœ ì‚¬ë„ ì§€í‘œ**: ì˜ˆì¸¡ëœ ì²´ì ê³¼ ì‹¤ì œ ì²´ì ì˜ ì°¨ì´ë¥¼ ì¸¡ì •
                - ìƒëŒ€ì  ì²´ì  ì°¨ì´(RVD) = $\\frac{|V_{pred} - V_{true}|}{V_{true}}$
            
            #### ê²€ì¦ ë°©ë²•
            
            - **êµì°¨ ê²€ì¦**: ë°ì´í„°ë¥¼ ì—¬ëŸ¬ í´ë“œë¡œ ë‚˜ëˆ„ì–´ ëª¨ë¸ ì„±ëŠ¥ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ í‰ê°€
                - k-fold êµì°¨ ê²€ì¦
                - Leave-one-out êµì°¨ ê²€ì¦
            
            - **í™€ë“œì•„ì›ƒ ê²€ì¦**: ë°ì´í„°ë¥¼ í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• 
            
            - **ê³¼ì í•© ë°©ì§€ ì „ëµ**:
                - ë°ì´í„° ì¦ê°•
                - ì •ê·œí™” ê¸°ë²• ì ìš©
                - ì¡°ê¸° ì¢…ë£Œ(Early stopping)
            
            #### ì„ìƒì  ìœ íš¨ì„± ê²€ì¦
            
            - **ê´€ì°°ì ê°„ ì¼ì¹˜ë„**: ì—¬ëŸ¬ ì „ë¬¸ê°€ì˜ ë¶„í•  ê²°ê³¼ì™€ ì•Œê³ ë¦¬ì¦˜ ê²°ê³¼ ë¹„êµ
            - **ì„ìƒì  ì˜í–¥ í‰ê°€**: ë¶„í•  ê²°ê³¼ê°€ ì„ìƒì  ì˜ì‚¬ê²°ì •ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
            - **ì‹œê°„ íš¨ìœ¨ì„±**: ìˆ˜ë™ ë¶„í•  ëŒ€ë¹„ ì‹œê°„ ì ˆì•½ íš¨ê³¼
            """)
            
            formula_explanation = """
            #### ìˆ˜ì‹ ì„¤ëª…
            - DSCì™€ IoU: XëŠ” ì˜ˆì¸¡ ë§ˆìŠ¤í¬, YëŠ” ì‹¤ì œ ë§ˆìŠ¤í¬ë¥¼ ì˜ë¯¸
            - Hausdorff ê±°ë¦¬: ë‘ ì§‘í•© X, Y ê°„ì˜ ìµœëŒ€ ê±°ë¦¬ë¥¼ ì¸¡ì •
            - TP = True Positive, TN = True Negative, FP = False Positive, FN = False Negative
            """
            
            st.markdown(formula_explanation)
            
            # ì‹œê°í™” ì˜ˆì‹œ
            st.code("""
            # í‰ê°€ ì§€í‘œ ì‹œê°í™” ì˜ˆì œ
            import matplotlib.pyplot as plt
            import numpy as np
            from sklearn.metrics import confusion_matrix
            import seaborn as sns
            
            # í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
            def plot_confusion_matrix(y_true, y_pred, classes):
                cm = confusion_matrix(y_true.flatten(), y_pred.flatten())
                plt.figure(figsize=(8, 6))
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                            xticklabels=classes, yticklabels=classes)
                plt.ylabel('ì‹¤ì œ ë ˆì´ë¸”')
                plt.xlabel('ì˜ˆì¸¡ ë ˆì´ë¸”')
                plt.title('í˜¼ë™ í–‰ë ¬')
                plt.show()
                
            # Dice ê³„ìˆ˜ ê³„ì‚° ë° ì‹œê°í™”
            def plot_dice_scores(dice_scores, classes):
                plt.figure(figsize=(10, 6))
                bar_colors = plt.cm.viridis(np.linspace(0, 0.8, len(classes)))
                plt.bar(classes, dice_scores, color=bar_colors)
                plt.axhline(y=np.mean(dice_scores), color='r', linestyle='--', 
                        label=f'í‰ê· : {np.mean(dice_scores):.3f}')
                plt.ylim([0, 1.0])
                plt.xlabel('í´ë˜ìŠ¤')
                plt.ylabel('Dice ê³„ìˆ˜')
                plt.title('í´ë˜ìŠ¤ë³„ Dice ê³„ìˆ˜')
                plt.legend()
                plt.show()
            """, language="python")

    elif material_type == "ë…¼ë¬¸ ë° ì°¸ê³ ìë£Œ":
        st.subheader("ì˜ë£Œ ì˜ìƒ ë¶„í•  ê´€ë ¨ ë…¼ë¬¸ ë° ì°¸ê³ ìë£Œ")
        
        reference_categories = [
            "ê¸°ì´ˆ ë…¼ë¬¸",
            "ìµœì‹  ì—°êµ¬ ë™í–¥",
            "ì˜¤í”ˆ ì†ŒìŠ¤ ë„êµ¬",
            "ë°ì´í„°ì…‹ ë° ì±Œë¦°ì§€"
        ]
        
        selected_category = st.selectbox("ì¹´í…Œê³ ë¦¬", reference_categories)
        
        if selected_category == "ê¸°ì´ˆ ë…¼ë¬¸":
            st.write("""
            ### ì˜ë£Œ ì˜ìƒ ë¶„í• ì˜ ê¸°ì´ˆ ë…¼ë¬¸
            
            #### U-Net ë° ë”¥ëŸ¬ë‹ ê¸°ì´ˆ ì•„í‚¤í…ì²˜
            
            1. **U-Net: Convolutional Networks for Biomedical Image Segmentation**
            - ì €ì: Ronneberger, O., Fischer, P., & Brox, T.
            - ì¶œíŒ ì—°ë„: 2015
            - ì£¼ìš” ë‚´ìš©: ìŠ¤í‚µ ì—°ê²°ì„ í™œìš©í•œ ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ì˜ CNN ì•„í‚¤í…ì²˜ ì œì•ˆ
            - ë§í¬: [Paper](https://arxiv.org/abs/1505.04597)

            2. **V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation**
            - ì €ì: Milletari, F., Navab, N., & Ahmadi, S. A.
            - ì¶œíŒ ì—°ë„: 2016
            - ì£¼ìš” ë‚´ìš©: 3D ì˜ë£Œ ì˜ìƒì„ ìœ„í•œ U-Netì˜ í™•ì¥ ë²„ì „, Dice ì†ì‹¤ í•¨ìˆ˜ ë„ì…
            - ë§í¬: [Paper](https://arxiv.org/abs/1606.04797)

            3. **3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation**
            - ì €ì: Ã‡iÃ§ek, Ã–., Abdulkadir, A., Lienkamp, S. S., Brox, T., & Ronneberger, O.
            - ì¶œíŒ ì—°ë„: 2016
            - ì£¼ìš” ë‚´ìš©: 3D ë³¼ë¥¨ ë°ì´í„°ë¥¼ ìœ„í•œ U-Net í™•ì¥, í¬ì†Œ ì–´ë…¸í…Œì´ì…˜ í™œìš©
            - ë§í¬: [Paper](https://arxiv.org/abs/1606.06650)

            4. **Attention U-Net: Learning Where to Look for the Pancreas**
            - ì €ì: Oktay, O., Schlemper, J., Folgoc, L. L., Lee, M., Heinrich, M., Misawa, K., ... & Glocker, B.
            - ì¶œíŒ ì—°ë„: 2018
            - ì£¼ìš” ë‚´ìš©: ì–´í…ì…˜ ê²Œì´íŠ¸ë¥¼ U-Netì— í†µí•©í•˜ì—¬ íƒ€ê²Ÿ êµ¬ì¡°ë¬¼ì— ì§‘ì¤‘
            - ë§í¬: [Paper](https://arxiv.org/abs/1804.03999)
            """)
            
        elif selected_category == "ìµœì‹  ì—°êµ¬ ë™í–¥":
            st.write("""
            ### ì˜ë£Œ ì˜ìƒ ë¶„í• ì˜ ìµœì‹  ì—°êµ¬ ë™í–¥
            
            #### íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ëª¨ë¸
            
            1. **TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation**
            - ì €ì: Chen, J., Lu, Y., Yu, Q., Luo, X., Adeli, E., Wang, Y., ... & Zhou, Y.
            - ì¶œíŒ ì—°ë„: 2021
            - ì£¼ìš” ë‚´ìš©: CNNê³¼ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜
            - ë§í¬: [Paper](https://arxiv.org/abs/2102.04306)

            2. **UNETR: Transformers for 3D Medical Image Segmentation**
            - ì €ì: Hatamizadeh, A., Tang, Y., Nath, V., Yang, D., Myronenko, A., Landman, B., ... & Xu, D.
            - ì¶œíŒ ì—°ë„: 2022
            - ì£¼ìš” ë‚´ìš©: 3D ì˜ë£Œ ì˜ìƒì„ ìœ„í•œ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ U-Net êµ¬ì¡°
            - ë§í¬: [Paper](https://arxiv.org/abs/2103.10504)

            3. **Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in MRI Images**
            - ì €ì: Hatamizadeh, A., Nath, V., Tang, Y., Yang, D., Roth, H., & Xu, D.
            - ì¶œíŒ ì—°ë„: 2022
            - ì£¼ìš” ë‚´ìš©: Swin íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ í™œìš©í•œ ê³„ì¸µì  íŠ¹ì§• ì¶”ì¶œ ì•„í‚¤í…ì²˜
            - ë§í¬: [Paper](https://arxiv.org/abs/2201.01266)

            #### ì•½ì§€ë„ ë° ìê°€ì§€ë„ í•™ìŠµ
            
            1. **nnU-Net: Self-adapting Framework for U-Net-Based Medical Image Segmentation**
            - ì €ì: Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H.
            - ì¶œíŒ ì—°ë„: 2021
            - ì£¼ìš” ë‚´ìš©: ë°ì´í„°ì…‹ì— ìë™ìœ¼ë¡œ ì ì‘í•˜ëŠ” U-Net í”„ë ˆì„ì›Œí¬
            - ë§í¬: [Paper](https://arxiv.org/abs/1809.10486)

            2. **SwinSupLoss: Supervised Pre-training and Contrastive Learning in one Loss for Medical Image Segmentation**
            - ì €ì: Azad, R., Aghdam, E. K., Cohen, J. P., Clifton, D., & Dagan, M.
            - ì¶œíŒ ì—°ë„: 2023
            - ì£¼ìš” ë‚´ìš©: ê°ë… í•™ìŠµê³¼ ëŒ€ì¡° í•™ìŠµì„ ê²°í•©í•œ ìƒˆë¡œìš´ ì†ì‹¤ í•¨ìˆ˜
            - ë§í¬: [Paper](https://arxiv.org/abs/2303.17051)

            #### ë‹¤ì¤‘ ëª¨ë‹¬ë¦¬í‹° ë° ë„ë©”ì¸ ì ì‘
            
            1. **Synergistic Image and Feature Adaptation: Towards Cross-Modality Domain Adaptation for Medical Image Segmentation**
            - ì €ì: Chen, C., Dou, Q., Chen, H., Qin, J., & Heng, P. A.
            - ì¶œíŒ ì—°ë„: 2019
            - ì£¼ìš” ë‚´ìš©: ë‹¤ì–‘í•œ ì˜ìƒ ëª¨ë‹¬ë¦¬í‹° ê°„ì˜ ë„ë©”ì¸ ì ì‘ ê¸°ë²•
            - ë§í¬: [Paper](https://arxiv.org/abs/1901.08211)
            """)
            
        elif selected_category == "ì˜¤í”ˆ ì†ŒìŠ¤ ë„êµ¬":
            st.write("""
            ### ì˜ë£Œ ì˜ìƒ ë¶„í• ì„ ìœ„í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ë„êµ¬
            
            #### ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í”„ë ˆì„ì›Œí¬
            
            1. **MONAI (Medical Open Network for AI)**
            - ì„¤ëª…: PyTorch ê¸°ë°˜ì˜ ì˜ë£Œ ì˜ìƒ ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
            - íŠ¹ì§•: ì˜ë£Œ ì˜ìƒ íŠ¹í™” ë°ì´í„° ë³€í™˜, ì‚¬ì „ í•™ìŠµ ëª¨ë¸, í‰ê°€ ì§€í‘œ ì œê³µ
            - ë§í¬: [GitHub](https://github.com/Project-MONAI/MONAI)
            - ë¬¸ì„œ: [Documentation](https://docs.monai.io/)

            2. **NiftyNet**
            - ì„¤ëª…: TensorFlow ê¸°ë°˜ì˜ ì˜ë£Œ ì˜ìƒ ë¶„ì„ í”Œë«í¼
            - íŠ¹ì§•: ì˜ë£Œ ì˜ìƒ ì„¸ë¶„í™”, ë¶„ë¥˜, ìƒì„± ëª¨ë¸ ì§€ì›
            - ë§í¬: [GitHub](https://github.com/NifTK/NiftyNet)
            - ë…¼ë¬¸: [Gibson et al., 2018](https://www.sciencedirect.com/science/article/pii/S0169260717311823)

            3. **TorchIO**
            - ì„¤ëª…: PyTorchë¥¼ ìœ„í•œ ì˜ë£Œ ì˜ìƒ ì²˜ë¦¬ ë° ì¦ê°• ë¼ì´ë¸ŒëŸ¬ë¦¬
            - íŠ¹ì§•: 3D ì˜ë£Œ ì˜ìƒì„ ìœ„í•œ íš¨ìœ¨ì ì¸ ë°ì´í„° ë¡œë”© ë° ë³€í™˜
            - ë§í¬: [GitHub](https://github.com/fepegar/torchio)
            - ë¬¸ì„œ: [Documentation](https://torchio.readthedocs.io/)

            4. **nnU-Net**
            - ì„¤ëª…: ìê¸° êµ¬ì„± U-Net ê¸°ë°˜ ì˜ë£Œ ì˜ìƒ ë¶„í•  í”„ë ˆì„ì›Œí¬
            - íŠ¹ì§•: ë°ì´í„°ì…‹ì— ìë™ìœ¼ë¡œ ì ì‘í•˜ëŠ” ì•„í‚¤í…ì²˜ ë° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
            - ë§í¬: [GitHub](https://github.com/MIC-DKFZ/nnUNet)
            - ë…¼ë¬¸: [Isensee et al., 2021](https://www.nature.com/articles/s41592-020-01008-z)

            #### ì‹œê°í™” ë° í‰ê°€ ë„êµ¬
            
            1. **3D Slicer**
            - ì„¤ëª…: ì˜ë£Œ ì˜ìƒ ì‹œê°í™” ë° ë¶„ì„ì„ ìœ„í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´
            - íŠ¹ì§•: Python ë° C++ í™•ì¥ ëª¨ë“ˆ, ë”¥ëŸ¬ë‹ ëª¨ë¸ í†µí•© ê°€ëŠ¥
            - ë§í¬: [Homepage](https://www.slicer.org/)
            - í™•ì¥: [AI í™•ì¥ ëª¨ë“ˆ](https://github.com/NVIDIA/ai-assisted-annotation-client)

            2. **ITK-SNAP**
            - ì„¤ëª…: ì˜ë£Œ ì˜ìƒ ë¶„í• ì„ ìœ„í•œ ëŒ€í™”í˜• ì†Œí”„íŠ¸ì›¨ì–´
            - íŠ¹ì§•: ë°˜ìë™ ë° ìˆ˜ë™ ë¶„í•  ë„êµ¬ ì œê³µ
            - ë§í¬: [Homepage](http://www.itksnap.org/)

            3. **MedicalZoo**
            - ì„¤ëª…: PyTorch ê¸°ë°˜ì˜ ì˜ë£Œ ì˜ìƒ ë¶„í•  ëª¨ë¸ ëª¨ìŒ
            - íŠ¹ì§•: ë‹¤ì–‘í•œ 3D ë¶„í•  ì•„í‚¤í…ì²˜ êµ¬í˜„ ë° ë¹„êµ
            - ë§í¬: [GitHub](https://github.com/black0017/MedicalZoo-PyTorch)
            """)
            
        elif selected_category == "ë°ì´í„°ì…‹ ë° ì±Œë¦°ì§€":
            st.write("""
            ### ì˜ë£Œ ì˜ìƒ ë¶„í•  ë°ì´í„°ì…‹ ë° ì±Œë¦°ì§€
            
            #### ê³µê°œ ë°ì´í„°ì…‹
            
            1. **Medical Segmentation Decathlon**
            - ì„¤ëª…: 10ê°œ ë‹¤ë¥¸ ì˜ë£Œ ì˜ìƒ ë¶„í•  ì‘ì—…ì„ í¬í•¨í•œ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹
            - ëª¨ë‹¬ë¦¬í‹°: CT, MRI
            - í•´ë¶€í•™ì  êµ¬ì¡°: ë‡Œ, ì‹¬ì¥, ê°„, ì·Œì¥, ì „ë¦½ì„  ë“±
            - ë§í¬: [Homepage](http://medicaldecathlon.com/)

            2. **BRATS (Brain Tumor Segmentation Challenge)**
            - ì„¤ëª…: ë‹¤ì¤‘ ëª¨ë‹¬ë¦¬í‹° MRIì—ì„œ ë‡Œì¢…ì–‘ ë¶„í• ì„ ìœ„í•œ ë°ì´í„°ì…‹
            - ëª¨ë‹¬ë¦¬í‹°: T1, T1ce, T2, FLAIR MRI
            - í•´ë¶€í•™ì  êµ¬ì¡°: ë‡Œ, ë‡Œì¢…ì–‘
            - ë§í¬: [Homepage](https://www.med.upenn.edu/cbica/brats2021/)

            3. **PROMISE12 (Prostate MR Image Segmentation)**
            - ì„¤ëª…: ì „ë¦½ì„  MRI ë¶„í•  ë°ì´í„°ì…‹
            - ëª¨ë‹¬ë¦¬í‹°: T2 MRI
            - í•´ë¶€í•™ì  êµ¬ì¡°: ì „ë¦½ì„ 
            - ë§í¬: [Homepage](https://promise12.grand-challenge.org/)

            4. **ACDC (Automated Cardiac Diagnosis Challenge)**
            - ì„¤ëª…: ì‹¬ì¥ MRI ë¶„í•  ë°ì´í„°ì…‹
            - ëª¨ë‹¬ë¦¬í‹°: ì‹¬ì¥ MRI
            - í•´ë¶€í•™ì  êµ¬ì¡°: ì¢Œì‹¬ì‹¤, ìš°ì‹¬ì‹¤, ì‹¬ê·¼
            - ë§í¬: [Homepage](https://www.creatis.insa-lyon.fr/Challenge/acdc/)

            #### ì£¼ìš” ì±Œë¦°ì§€
            
            1. **MICCAI Grand Challenges**
            - ì„¤ëª…: ì˜ë£Œ ì˜ìƒ ë¶„ì„ ë¶„ì•¼ì˜ ë‹¤ì–‘í•œ ê²½ìŸ ëŒ€íšŒ í”Œë«í¼
            - íŠ¹ì§•: ë§¤ë…„ ìƒˆë¡œìš´ ë¶„í•  ì‘ì—… ë° ë°ì´í„°ì…‹ ì œê³µ
            - ë§í¬: [Homepage](https://grand-challenge.org/)

            2. **ISBI Cell Tracking Challenge**
            - ì„¤ëª…: ì„¸í¬ ì¶”ì  ë° ë¶„í• ì„ ìœ„í•œ ë°ì´í„°ì…‹ ë° ì±Œë¦°ì§€
            - ëª¨ë‹¬ë¦¬í‹°: í˜„ë¯¸ê²½ ì˜ìƒ
            - ë§í¬: [Homepage](http://celltrackingchallenge.net/)

            3. **COVID-19 Lung CT Lesion Segmentation Challenge**
            - ì„¤ëª…: COVID-19 í™˜ìì˜ í CT ì˜ìƒì—ì„œ ë³‘ë³€ ë¶„í• 
            - ëª¨ë‹¬ë¦¬í‹°: í‰ë¶€ CT
            - ë§í¬: [Homepage](https://covid-segmentation.grand-challenge.org/)

            #### ë°ì´í„° ì ‘ê·¼ ë° í™œìš© íŒ
            
            - **IRB ë° ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­**: ì˜ë£Œ ë°ì´í„° ì‚¬ìš© ì‹œ ê´€ë ¨ ê·œì • ë° ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­ ìˆ™ì§€
            - **ë°ì´í„° ì „ì²˜ë¦¬**: ë‹¤ì–‘í•œ ìŠ¤ìºë„ˆì™€ í”„ë¡œí† ì½œë¡œ ì¸í•œ ì´ì§ˆì„± í•´ê²°ì„ ìœ„í•œ í‘œì¤€í™” ê³¼ì • í•„ìš”
            - **ë°ì´í„° ë¶ˆê· í˜•**: í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ìƒ˜í”Œë§ ë˜ëŠ” ê°€ì¤‘ì¹˜ ê¸°ë²• í™œìš©
            - **ë°ì´í„° ì¦ê°•**: ì œí•œëœ ë°ì´í„°ì—ì„œ ëª¨ë¸ ì¼ë°˜í™” ëŠ¥ë ¥ í–¥ìƒì„ ìœ„í•œ íš¨ê³¼ì ì¸ ì¦ê°• ì „ëµ ìˆ˜ë¦½
            """)
            
            st.warning("""
            ì°¸ê³ : ê° ë°ì´í„°ì…‹ ë° ì±Œë¦°ì§€ëŠ” ì‚¬ìš© ì¡°ê±´ê³¼ ë¼ì´ì„¼ìŠ¤ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
            ì—°êµ¬ ë˜ëŠ” ê°œë°œì— í™œìš©í•˜ê¸° ì „ í•´ë‹¹ ì¡°ê±´ì„ ë°˜ë“œì‹œ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
            """)

# Add a footer
st.markdown("---")
st.markdown("Â© 2025 ETRI ì˜ë£Œ ì˜ìƒ AI í•™ìŠµ ì‹œìŠ¤í…œ TANGO-MEDICAL")